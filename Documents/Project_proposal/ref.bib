@article{baba2025proveragent,
  title={Prover Agent: An Agent-based Framework for Formal Mathematical Proofs},
  author={Baba, Kaito and Liu, Chong and Kurita, Satoshi and Sannai, Akinori},
  year={2025},
  eprint={2506.19923},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://doi.org/10.48550/arXiv.2506.19923}
}

@article{rajeev2025cats,
  title={Cats Confuse Reasoning LLM: Query Agnostic Adversarial Triggers for Reasoning Models},
  author={Rajeev, Maitreya and Ramamurthy, Rajasekharan and Trivedi, Pulkit and Yadav, Vivek and Bamgbose, Olatunji and Madhusudan, Sudarshan T and Zou, James and Rajani, Nazneen Fatema},
  year={2025},
  eprint={2503.01781},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://doi.org/10.48550/arXiv.2503.01781}
}

@article{ren2025deepseek,
  title={DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition},
  author={Ren, Zhezheng and Shao, Zhongyu and Song, Junhua and Xin, Hang and Wang, Hao and Zhao, Wen and Zhang, Liang and Fu, Zhiyang and Zhu, Qiang and Yang, Donghong and others},
  year={2025},
  eprint={2504.21801},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://doi.org/10.48550/arXiv.2504.21801}
}

@article{liu2025safe,
  title={Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification},
  author={Liu, Chen and Yuan, Yizhi and Yin, Yingtong and Xu, Yang and Xu, Xin and Chen, Zelin and Wang, Yue and Shang, Li and Liu, Qun and Zhang, Ming},
  year={2025},
  eprint={2506.04592},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://doi.org/10.48550/arXiv.2506.04592}
}

@article{patel2025leantutor,
  title={LeanTutor: A Formally-Verified AI Tutor for Mathematical Proofs},
  author={Patel, Mihir and Bhattacharyya, Rounak and Lu, Tianshi and Mehta, Aarav and Voss, Nathaniel and Norouzi, Negar and Ranade, Gauri},
  year={2025},
  eprint={2506.08321},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://doi.org/10.48550/arXiv.2506.08321}
}

@article{thakur2024context,
  title={An In-Context Learning Agent for Formal Theorem-Proving},
  author={Thakur, Anshuman and Tsoukalas, Giorgos and Wen, Yufei and Xin, Jiongkun and Chaudhuri, Swarat},
  year={2024},
  eprint={2310.04353},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://doi.org/10.48550/arXiv.2310.04353}
}

@article{thakur2025langagent,
  title={A Language-Agent Approach to Formal Theorem-Proving},
  author={Thakur, Anshuman and Wen, Yufei and Chaudhuri, Swarat},
  year={2025},
  eprint={2310.04353},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://doi.org/10.48550/arXiv.2310.04353}
}

@article{chenSeedProverDeepBroad2025,
  title = {Seed-{{Prover}}: {{Deep}} and {{Broad Reasoning}} for {{Automated Theorem Proving}}},
  shorttitle = {Seed-{{Prover}}},
  author = {Chen, Luoxin and Gu, Jinming and Huang, Liankai and Huang, Wenhao and Jiang, Zhicheng and Jie, Allan and Jin, Xiaoran and Jin, Xing and Li, Chenggang and Ma, Kaijing and Ren, Cheng and Shen, Jiawei and Shi, Wenlei and Sun, Tong and Sun, He and Wang, Jiahui and Wang, Siran and Wang, Zhihong and Wei, Chenrui and Wei, Shufa and Wu, Yonghui and Wu, Yuchen and Xia, Yihang and Xin, Huajian and Yang, Fan and Ying, Huaiyuan and Yuan, Hongyi and Yuan, Zheng and Zhan, Tianyang and Zhang, Chi and Zhang, Yue and Zhang, Ge and Zhao, Tianyun and Zhao, Jianqiu and Zhou, Yichi and Zhu, Thomas Hanwen},
  date = {2025-08-01},
  eprint = {2507.23726},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2507.23726},
  url = {http://arxiv.org/abs/2507.23726},
  urldate = {2025-08-04},
  abstract = {LLMs have demonstrated strong mathematical reasoning abilities by leveraging reinforcement learning with long chain-of-thought, yet they continue to struggle with theorem proving due to the lack of clear supervision signals when solely using natural language. Dedicated domain-specific languages like Lean provide clear supervision via formal verification of proofs, enabling effective training through reinforcement learning. In this work, we propose \textbackslash textbf\{Seed-Prover\}, a lemma-style whole-proof reasoning model. Seed-Prover can iteratively refine its proof based on Lean feedback, proved lemmas, and self-summarization. To solve IMO-level contest problems, we design three test-time inference strategies that enable both deep and broad reasoning. Seed-Prover proves \$78.1\textbackslash\%\$ of formalized past IMO problems, saturates MiniF2F, and achieves over 50\textbackslash\% on PutnamBench, outperforming the previous state-of-the-art by a large margin. To address the lack of geometry support in Lean, we introduce a geometry reasoning engine \textbackslash textbf\{Seed-Geometry\}, which outperforms previous formal geometry engines. We use these two systems to participate in IMO 2025 and fully prove 5 out of 6 problems. This work represents a significant advancement in automated mathematical reasoning, demonstrating the effectiveness of formal verification with long chain-of-thought reasoning.},
  langid = {american},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\liuSu\\Zotero\\storage\\PXNUUQA3\\Chen et al. - 2025 - Seed-Prover Deep and Broad Reasoning for Automated Theorem Proving.pdf;C\:\\Users\\liuSu\\Zotero\\storage\\RV5UIWTR\\2507.html}
}

